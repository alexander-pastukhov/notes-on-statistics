<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 18 Ordered Categorical Data, i.e., Likert-scales | Notes on Statistics</title>
<meta name="author" content="Alexander Pastukhov">
<meta name="description" content="One very popular type of response in psychology and social sciences are so-called Likert-scale responses. For example, you may be asked to respond on how attractive you find a person in a photo...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 18 Ordered Categorical Data, i.e., Likert-scales | Notes on Statistics">
<meta property="og:type" content="book">
<meta property="og:description" content="One very popular type of response in psychology and social sciences are so-called Likert-scale responses. For example, you may be asked to respond on how attractive you find a person in a photo...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 18 Ordered Categorical Data, i.e., Likert-scales | Notes on Statistics">
<meta name="twitter:description" content="One very popular type of response in psychology and social sciences are so-called Likert-scale responses. For example, you may be asked to respond on how attractive you find a person in a photo...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="bs4_style.css%20-%20style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Notes on Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Precis</a></li>
<li><a class="" href="loss-functions.html"><span class="header-section-number">2</span> Loss functions</a></li>
<li><a class="" href="directed-acyclic-graphs-and-causal-reasoning.html"><span class="header-section-number">3</span> Directed Acyclic Graphs and Causal Reasoning</a></li>
<li><a class="" href="spurious-association.html"><span class="header-section-number">4</span> Multiple regression - Spurious association</a></li>
<li><a class="" href="the-haunted-dag.html"><span class="header-section-number">5</span> The haunted DAG</a></li>
<li><a class="" href="information-criteria.html"><span class="header-section-number">6</span> Information Criteria</a></li>
<li><a class="" href="bayesian-vs.-fequentist-statisics.html"><span class="header-section-number">7</span> Bayesian vs. fequentist statisics</a></li>
<li><a class="" href="mixtures.html"><span class="header-section-number">8</span> Mixtures</a></li>
<li><a class="" href="instrumental-variables.html"><span class="header-section-number">9</span> Instrumental Variables</a></li>
<li><a class="" href="parameters-combining-information-from-an-individual-with-population.html"><span class="header-section-number">10</span> Parameters: combining information from an individual with population</a></li>
<li><a class="" href="incorporating-measurement-error-a-rubber-band-metaphor.html"><span class="header-section-number">11</span> Incorporating measurement error: a rubber band metaphor</a></li>
<li><a class="" href="generalized-additive-models-as-continuous-random-effects.html"><span class="header-section-number">12</span> Generalized Additive Models as continuous random effects</a></li>
<li><a class="" href="flat-priors-the-strings-attached.html"><span class="header-section-number">13</span> Flat priors: the strings attached</a></li>
<li><a class="" href="unbiased-mean-versus-biased-variance-in-plain-english.html"><span class="header-section-number">14</span> Unbiased mean versus biased variance in plain English</a></li>
<li><a class="" href="probability-mass-versus-probability-density.html"><span class="header-section-number">15</span> Probability mass versus probability density</a></li>
<li><a class="" href="effective-degrees-of-freedom-number-of-parameters.html"><span class="header-section-number">16</span> Effective degrees of freedom / number of parameters</a></li>
<li><a class="" href="multiple-regression---masked-relationship.html"><span class="header-section-number">17</span> Multiple regression - Masked relationship</a></li>
<li><a class="active" href="ordered-categorical-data-i.e.-likert-scales.html"><span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales</a></li>
<li><a class="" href="intuition-for-how-cholesky-decomposition-makes-possible-to-generate-correlated-random-variables.html"><span class="header-section-number">19</span> Intuition for how Cholesky decomposition makes possible to generate correlated random variables</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/alexander-pastukhov/notes-on-statistics">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ordered-categorical-data-i.e.-likert-scales" class="section level1" number="18">
<h1>
<span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales<a class="anchor" aria-label="anchor" href="#ordered-categorical-data-i.e.-likert-scales"><i class="fas fa-link"></i></a>
</h1>
<p>One very popular type of response in psychology and social sciences are so-called Likert-scale responses. For example, you may be asked to respond on how attractive you find a person in a photo from 1 (very unattractive) to 7 (very attractive). Or to respond on how satisfied you are with a service from 1 (very unsatisfied) to 4 (very satisfied). Or rate your confidence on a 5-point scale, etc. Likert-scale responses are extremely common and are quite often analyzed via linear models (i.e., a <em>t</em>-test, a repeated measures ANOVA, or linear-mixed models) assuming that response levels correspond directly to real numbers. The purpose of these notes is to document conceptual and technical problems this approach entails.</p>
<div id="conceptualization-of-responses-internal-continuous-variable-discritized-into-external-responses-via-a-set-of-cut-points" class="section level2" number="18.1">
<h2>
<span class="header-section-number">18.1</span> Conceptualization of responses: internal continuous variable discritized into external responses via a set of cut-points<a class="anchor" aria-label="anchor" href="#conceptualization-of-responses-internal-continuous-variable-discritized-into-external-responses-via-a-set-of-cut-points"><i class="fas fa-link"></i></a>
</h2>
<p>First, let us think what behavioral responses correspond to as it will become very important once we discuss conceptual problems with a common “direct” approach of using linear models for Likert-scale data.</p>
<p>When we ask a participant to respond “On a scale from 1 to 7, how attractive do you find the face in the photo?”, we assume that there is a <em>continuous</em> internal variable (for example, encoded via a neural ensemble) that represents attractiveness of a face (our satisfaction with service, our confidence, etc.). The strength of that representation varies in a continuous manner from its minimum (e.g., baseline firing rate, if we assume that strength is encoded by spiking rate) to maximum (maximum firing rate for that neural ensemble). When we impose a seven-point scale on participants, we force them to discretize (bin) this continuous variable, creating a <em>many-to-one</em> mapping. In other words, a participant decides that values (intensities) within a particular range all get mapped on <span class="math inline">\(1\)</span>, a different but adjacent range of higher value corresponds to <span class="math inline">\(2\)</span>, etc. You can think about it as values within that range being “rounded”<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;regressed?&lt;/p&gt;"><sup>34</sup></a> towards the mean that defines the responses. Or, equivalently, you can think in terms of cut points that define range for individual values. This is how the discretization is depicted in the figure below. If the signal is below the first cut point, our participant’s response is “1”. When it is between the first and second cut points, the response is “2” and so on. When it is to the right of the last sixth cut point, it is “7”. This conceptualization means that responses are an ordered categorical variable, as any underlying intensity for a response “1” is necessarily smaller than <em>any</em> intensity for response “2” and both are smaller than, again, <em>any</em> intensity for response “3”, etc.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-75-1.png" width="672"></div>
<p>As per usual, even when we use the same stimulus and ask the same question, participant’s internal continuous response varies from trial to trial due to noise. We model this by assuming that on a given trial a value is drawn from a normal distribution centered at the “true” intensity level<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Here, I will assume that cut points are fixed and it is parameters of the normal distribution that get adjusted. The actual implementation of ordered logit/probit models has it the other way around, so that intensity always comes from a normal distribution centered at &lt;span class="math inline"&gt;\(0\)&lt;/span&gt; and with a standard deviation of &lt;span class="math inline"&gt;\(1\)&lt;/span&gt; and it is cut-points that get adjusted. The two are mostly mathematically equivalent but I find the former to be more intuitive.&lt;/p&gt;'><sup>35</sup></a>. When the noisy intensity is converted to discrete responses, their variability will depend on the location (mean) and the width (standard deviation) of this distribution. The broader this distribution and / or closer it is to a cut point, the more activity will “spill over” a cut point into adjacent regions and the more variable discrete responses will be.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-76-1.png" width="672"></div>
<p>Given this conceptualization, our goal is to recover cut points and model shifts of the mean for the <em>continuous</em> internal variable (in response to our experimental manipulation) using only observed <em>discrete</em> responses.</p>
</div>
<div id="conceptual-problem-with-linear-models-we-change-our-mind-about-what-responses-correspond-to." class="section level2" number="18.2">
<h2>
<span class="header-section-number">18.2</span> Conceptual problem with linear models: we change our mind about what responses correspond to.<a class="anchor" aria-label="anchor" href="#conceptual-problem-with-linear-models-we-change-our-mind-about-what-responses-correspond-to."><i class="fas fa-link"></i></a>
</h2>
<p>A very common approach is to fit Likert-scale data using a linear model (a <em>t</em>-test, a repeated-measures ANOVA, linear-mixed models, etc.) while assuming that responses correspond directly to real numbers. In other words, when participants responded “very unattractive”, or “not confident at all”, or “do not agree at all” they literally meant a real number <span class="math inline">\(1.0\)</span>. When they used the middle (let’s say the third on a five-point scale) option “neither agree, nor disagree” they literally meant <span class="math inline">\(3.0\)</span>.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-77-1.png" width="672"></div>
<p>This assumption appears to simplify our life dramatically but at the expense of changing the narrative. Recall that our original (and, for me, very intuitive) conceptualization was that responses reflect a many-to-one mapping between an underlying continuous variable and a discrete (ordered categorical) response. But by converting them directly to real numbers and using them as an outcome variable of a linear model we assume a <em>one-to-one</em> mapping between the <em>continuous</em> real-valued internal variable and <em>continuous</em>(!) real-valued observed responses. This means that from a linear model point of view, for a 7-point Likert scale <em>any</em> real value is a valid and possible response and therefore a participant <em>could have</em> responded with 6.5, 3.14, or 2.71828 but, for whatever reason (sheer luck?), we only observed a handful of (integer) values.</p>
<p><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-78-1.png" width="672"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-78-2.png" width="672"></p>
<p>Notice that this is <em>not</em> how we thought participants behave. I think everyone<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Never say always!&lt;/p&gt;"><sup>36</sup></a> would object to the idea that the limited repertoire of responses is due to endogenous processing rather than exogenous limitations imposed by an experimental design. Yet, this is how a <em>linear model</em> “thinks” about it given the outcome variable you gave it and, if you are not careful, it is easy to miss this change in the narrative. It is, however, important as it means that estimates produced by such a model are about that alternative one-to-one kind of continuous responses, not the many-to-one discrete ones that you had in mind! That alternative is not a bad story per se, it is just a <em>different</em> story that should not be confused with the original one.</p>
<p>This change in the narrative of what responses correspond to is also a problem if you want to use a (fitted) linear model to generate predictions and simulate the data. It will happily spit out real valued responses like 6.5, 3.14, or 2.71828<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;If you feel lucky enough to expect an integer response, you’d better use this luck on playing an actual lottery&lt;/p&gt;"><sup>37</sup></a>. You have two options. You can bite the bullet and take them at their face value, sticking to “response is a real-valued variable” and one-to-one mapping between an internal variable and an observed response. That lets you keep the narrative but means that real and ideal observers play by different rules. Their responses are different and that means your conclusions based on an ideal observer behavior are of limited use. Alternatively, you can round real-valued responses off to a closest integer getting discrete categorical-like responses. Unfortunately, that means changing the narrative yet again. In this case, you fitted the model assuming a one-to-one mapping but you use its predictions assuming many-to-one. Not good. It is really hard to understand what is going on, if you keep changing your mind on what the responses mean. A linear model will also generate out-of-range responses, like -1 or 8. Here, you have little choice but to clip them into the valid range, forcing the many-to-one mapping on at least some responses. Again, change of narrative means that model fitting and model interpretation rely on different conceptualizations of what the response is.</p>
<p>This may sound too conceptual but I suspect that few people who use linear models on Likert-scale data directly realize that their model is not doing what they think it is doing and, erroneously!, interpret one-to-one linear-model estimates as many-to-one. The difference may or may not be crucial but, unfortunately, one cannot know how important it is without comparing two kinds of models directly. And that raises a question: Why employ a model that does something different to what you need to to begin with? Remember, using an appropriate model and interpreting it correctly is <em>your</em> job, not that of a mathematical model, nor is it a job of a software package.</p>
</div>
<div id="a-technical-problem-data-that-bunches-up-near-a-range-limit." class="section level2" number="18.3">
<h2>
<span class="header-section-number">18.3</span> A technical problem: Data that bunches up near a range limit.<a class="anchor" aria-label="anchor" href="#a-technical-problem-data-that-bunches-up-near-a-range-limit."><i class="fas fa-link"></i></a>
</h2>
<p>When you use a linear model, you assume that residuals are normally distributed. This is something that you may not be sure of <em>before</em> you fit a specific model, as it is residuals not the data that must be normally distributed. However, in some cases you may be fairly certain that this will not be the case, such as when a variable has only a limited range of values and the mean (a model prediction) is close to one of these limits. Whenever you have observations that are close to that hard limit, they will “bunch up” against it because they cannot go lower or higher than that. See the figure below for an illustration of how it happens when a <em>continuous</em> variable <span class="math inline">\(x\)</span> is restricted to 1 to 7 range<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Note that for skewed distributions their mode is different from the mean!&lt;/p&gt;"><sup>38</sup></a>.
<img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-79-1.png" width="672"></p>
<p>The presence of a limit is not a deal breaker for using linear models per se. Most physical measures cannot be negative<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Try coming up with one and don’t say “temperature”!&lt;/p&gt;"><sup>39</sup></a> but as long your observations are sufficiently far away from zero, you are fine. You cannot have a negative height but you certainly can use linear models for adult height as, for example, an average female height in USA is 164±6.4 cm. In other words, the mean is more than 25 standards deviations away from the range limit of zero and the latter can be safely ignored.</p>
<p>Unfortunately, Likert-scale data combines an extremely limited range with a very coarse step. Even a 7-point Likert scale does not give you much wiggle room and routinely used 5-point scales are even narrower. This means that unless the mean is smack in the middle (e.g., at four for a 7-point scale), you are getting closer to one of the limits and your residuals become either positively (when approaching a lower limit) or negatively (for the upper one) skewed. In other words, the residuals are <em>systematically</em> not normally distributed and their distribution depends on the mean. This clearly violates an assumption of normality of residuals and of their conditional i.i.d. (Independent and Identically Distributed). This is a deal breaker for parametric frequentist statistics (a <em>t</em>-test, a repeated-measures ANOVA, linear-mixed models), as their inferences are built on that assumptions and, therefore, become unreliable and should not to be trusted.</p>
</div>
<div id="another-technical-problem-can-we-assume-that-responses-correspond-to-real-numbers-that-we-picked" class="section level2" number="18.4">
<h2>
<span class="header-section-number">18.4</span> Another technical problem: Can we assume that responses correspond to real numbers that we picked?<a class="anchor" aria-label="anchor" href="#another-technical-problem-can-we-assume-that-responses-correspond-to-real-numbers-that-we-picked"><i class="fas fa-link"></i></a>
</h2>
<p>The skewed residuals described above are a fundamental problem for parametric frequentist methods but are not critical if you use Bayesian or non-parametric bootstrapping/permutation linear models. Does this mean it is safe to use them? Probably not. When you use responses directly, you assume a direct correspondence between a response label (e.g., “agree”) and a real number <span class="math inline">\(4.0\)</span>. If your responses do correspond to the real numbers you have picked, you can perform the usual arithmetic with them. E.g., you can assume that <span class="math inline">\((4.0 + 4.0) / 2\)</span> is equal to <span class="math inline">\((3.0 + 5.0) / 2\)</span> to <span class="math inline">\((2.0 + 6.0) / 2\)</span> to <span class="math inline">\((1.0 + 7.0)/ 2\)</span>. However, what if this is <em>not</em> the case, what if the responses do not correspond to the real numbers that you’ve picked? Then our basic arithmetic stops working the way you think! Take a look at the figure below where “real value” of responses is not an integer that we have picked for it.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-80-1.png" width="672"></div>
<p>Unless you <em>know</em> that the response levels correspond to the selected real number and that the simple arithmetic holds, you are in danger of computing nonsense. This problem is more obvious when individual response levels are labelled, e.g., <code>"Strongly disagree"</code>, <code>"Disagree"</code>, <code>"Neither disagree, nor agree"</code>, <code>"Agree"</code>, <code>"Strongly agree"</code>. What is an average of <code>"Strongly disagree"</code> and <code>"Strongly agree"</code>? Is it the same as an average of <code>"Disagree"</code> and <code>"Agree"</code>? Is increase from <code>"Strongly disagree"</code> to <code>"Disagree"</code> identical to that from <code>"Neither disagree, nor agree"</code> to <code>"Agree"</code>? The answer is “who knows?!” but in my experience scales are rarely truly linear as people tend to avoid extremes and have their own idea about the range of internal variable levels that corresponds to a particular response.</p>
<p>As noted above, even when scale levels are explicitly named, it is very common to “convert” them to numbers because you cannot ask a computer to compute an average of <code>"Disagree"</code> and <code>"Agree"</code> (it will flatly refuse to do this) but it will compute an average of <span class="math inline">\(2\)</span> and <span class="math inline">\(4\)</span>. And there will be no error message! And it will return <span class="math inline">\(3\)</span>! Problem solved, right? Not really. Yes, the computer will not complain but this is because it has no idea what <span class="math inline">\(2\)</span> and <span class="math inline">\(4\)</span> stand for. You give it real numbers, it will do the math. So, if you pretend that <code>"Disagree"</code> and <code>"Agree"</code> correspond directly to <span class="math inline">\(2\)</span> and <span class="math inline">\(4\)</span> it will certainly <em>look like</em> normal math. And imagine that responses are <code>"Disagree"</code> and <code>"Strongly agree"</code>, so the numbers are <span class="math inline">\(2\)</span> and <span class="math inline">\(5\)</span> and the computer will return an average value of <span class="math inline">\(3.5\)</span>. It will be even easier to convince yourself that your responses are real numbers (see, there is a <em>decimal point</em> where!), just like linear models assume. Unfortunately, you are not fooling the computer (it seriously does not care), you are fooling yourself. Your math might check out, if the responses do correspond to the real numbers you have picked, or it might not. And in both cases, there will be no warning or an error message, just some numbers that you will interpret at their face value and reach possibly erroneous conclusions. Again, the problem is that you wouldn’t know whether the numbers you are looking at are valid or nonsense and the same dilemma (valid or nonsense?) will be applicable to any inferences and conclusions that you draw from them. In short, a direct correspondence between response levels and specific real numbers is a <em>very</em> strong assumption that should be validated, not taken on pure faith.</p>
</div>
<div id="solution-an-ordered-logitprobit-model" class="section level2" number="18.5">
<h2>
<span class="header-section-number">18.5</span> Solution: an ordered logit/probit model<a class="anchor" aria-label="anchor" href="#solution-an-ordered-logitprobit-model"><i class="fas fa-link"></i></a>
</h2>
<p>So far I have summarized problems of using linear models when assuming that responses correspond to real numbers. How can we solve them? By using ordered <a href="https://en.wikipedia.org/wiki/Ordered_logit">logistic</a>/<a href="https://en.wikipedia.org/wiki/Ordered_probit#:~:text=In%20statistics%2C%20ordered%20probit%20is,fair%2C%20good%2C%20excellent">probit</a> models. They are built using the many-to-one mapping between a continuous variable that has a limited range (for simplicity it ranges from 0 to 1) and is discretized to match behavioral responses using a set of cut points. In principle, the latter can be fixed but in most cases they should be fitted as part of the model. Both logit and probit models assume that the sampling distribution of the underlying continuous variable is a standard normal distribution and, therefore, both the continuous variable and cut points live on the infinite real number line that is transformed to 0..1 range via either a logit or a probit link function. Strictly speaking, the latter step is not necessary but makes things easier both for doing math and for understanding the outcome.</p>
<p>From a mathematical point of view, using logit and probit makes it easy to compute the area under the curve between two cut points. Logit or probit are cumulative functions, so for a standard normal distribution (centered at <span class="math inline">\(0\)</span> with standard deviation of <span class="math inline">\(1\)</span>) they compute an area under the curve starting from <span class="math inline">\(-\infty\)</span> up to some point <span class="math inline">\(k_i\)</span>.</p>
<p><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-81-1.png" width="672"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-81-2.png" width="672"></p>
<p>Therefore, if we want to compute an area between two cut points <span class="math inline">\(k_{i-1}\)</span> and <span class="math inline">\(k_i\)</span>, we can do it as <span class="math inline">\(logit(k_{i})-logit(k_{i-1})\)</span> (same goes for probit).</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-82-1.png" width="672"></div>
<p>Because both logit and probit are non-linear transformations cut points evenly distributed on a 0..1 range will be not be evenly distributed on the real numbers line and vice versa. Transforming from real space to 0..1 range also makes it easier to understand relative positions of cut points and changes in the continuous variable (that we translate into discrete responses via cut points).</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-83-1.png" width="672"></div>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-84-1.png" width="672"></div>
</div>
<div id="using-ordered-logitprobit-models" class="section level2" number="18.6">
<h2>
<span class="header-section-number">18.6</span> Using ordered logit/probit models<a class="anchor" aria-label="anchor" href="#using-ordered-logitprobit-models"><i class="fas fa-link"></i></a>
</h2>
<p>There are several R packages that implement regression models for ordinal data including specialized packages <a href="https://cran.r-project.org/package=ordinal">ordinal</a>, <a href="https://cran.r-project.org/package=oglmx">oglmx</a>, as well as via a <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_monotonic.html">ordered</a> option in <a href="https://cran.r-project.org/package=brms">brms</a> package.</p>
<p>From a coding point of view, fitting an ordered logit/probit the model is as easy as fitting any other regression model. However, the presence of the link function complicates its understanding as all parameters interact<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The usual curse of generalized linear models and, probably, one of the reasons while people tend to stick to linear models even if they are potentially or clearly invalid.&lt;/p&gt;"><sup>40</sup></a>. My current approach is not to try to interpret the parameters directly but to plot a triptych.</p>
<ol style="list-style-type: decimal">
<li>Compute posterior predictions and compare their distribution with behavioral data to understand how well the model fits the data.</li>
</ol>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-85"></span>
<img src="images/ordinal-predictions.png" alt="Behavioral data (circles and error bars depict group average and bootstrapped 89% confidence intervals) versus model posterior predictions (lines and ribbons depict mean and 89% compatibility intervals)." width="80%"><p class="caption">
Figure 18.1: Behavioral data (circles and error bars depict group average and bootstrapped 89% confidence intervals) versus model posterior predictions (lines and ribbons depict mean and 89% compatibility intervals).
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Visualize cut points on a 0..1 range to understand the mapping between continuous intensity and discrete responses as well as uncertainty about their position.</li>
</ol>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-86"></span>
<img src="images/ordinal-cutpoints.png" alt="Posterior distribution for cut points transformed to 0..1 range." width="50%"><p class="caption">
Figure 18.2: Posterior distribution for cut points transformed to 0..1 range.
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Visualize and compare changes in continuous intensity on a 0..1 range adding cut points to facilitate understanding.</li>
</ol>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-87"></span>
<img src="images/ordinal-change.png" alt="Posterior distribution and change for continuous intensity variable transformed to 0..1 range. Text above plot show mean and 89% credible interval for the change." width="50%"><p class="caption">
Figure 18.3: Posterior distribution and change for continuous intensity variable transformed to 0..1 range. Text above plot show mean and 89% credible interval for the change.
</p>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="multiple-regression---masked-relationship.html"><span class="header-section-number">17</span> Multiple regression - Masked relationship</a></div>
<div class="next"><a href="intuition-for-how-cholesky-decomposition-makes-possible-to-generate-correlated-random-variables.html"><span class="header-section-number">19</span> Intuition for how Cholesky decomposition makes possible to generate correlated random variables</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ordered-categorical-data-i.e.-likert-scales"><span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales</a></li>
<li><a class="nav-link" href="#conceptualization-of-responses-internal-continuous-variable-discritized-into-external-responses-via-a-set-of-cut-points"><span class="header-section-number">18.1</span> Conceptualization of responses: internal continuous variable discritized into external responses via a set of cut-points</a></li>
<li><a class="nav-link" href="#conceptual-problem-with-linear-models-we-change-our-mind-about-what-responses-correspond-to."><span class="header-section-number">18.2</span> Conceptual problem with linear models: we change our mind about what responses correspond to.</a></li>
<li><a class="nav-link" href="#a-technical-problem-data-that-bunches-up-near-a-range-limit."><span class="header-section-number">18.3</span> A technical problem: Data that bunches up near a range limit.</a></li>
<li><a class="nav-link" href="#another-technical-problem-can-we-assume-that-responses-correspond-to-real-numbers-that-we-picked"><span class="header-section-number">18.4</span> Another technical problem: Can we assume that responses correspond to real numbers that we picked?</a></li>
<li><a class="nav-link" href="#solution-an-ordered-logitprobit-model"><span class="header-section-number">18.5</span> Solution: an ordered logit/probit model</a></li>
<li><a class="nav-link" href="#using-ordered-logitprobit-models"><span class="header-section-number">18.6</span> Using ordered logit/probit models</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/alexander-pastukhov/notes-on-statistics/blob/master/17-ordered-categorical.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/alexander-pastukhov/notes-on-statistics/edit/master/17-ordered-categorical.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Notes on Statistics</strong>" was written by Alexander Pastukhov. It was last built on 2022-06-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
