<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 8 Mixtures | Notes on Statistics</title>
<meta name="author" content="Alexander Pastukhov">
<meta name="description" content="8.1 Beta Binomial Beta binomial is defined as a product of binomial and beta distributions. \[BetaBinomial(k|N, p, \theta) = Binomial(k|N,p) \cdot Beta(p|\beta_1, \beta_2),\] where \(k\) is number...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 8 Mixtures | Notes on Statistics">
<meta property="og:type" content="book">
<meta property="og:description" content="8.1 Beta Binomial Beta binomial is defined as a product of binomial and beta distributions. \[BetaBinomial(k|N, p, \theta) = Binomial(k|N,p) \cdot Beta(p|\beta_1, \beta_2),\] where \(k\) is number...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 8 Mixtures | Notes on Statistics">
<meta name="twitter:description" content="8.1 Beta Binomial Beta binomial is defined as a product of binomial and beta distributions. \[BetaBinomial(k|N, p, \theta) = Binomial(k|N,p) \cdot Beta(p|\beta_1, \beta_2),\] where \(k\) is number...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="bs4_style.css%20-%20style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Notes on Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Precis</a></li>
<li><a class="" href="loss-functions.html"><span class="header-section-number">2</span> Loss functions</a></li>
<li><a class="" href="directed-acyclic-graphs-and-causal-reasoning.html"><span class="header-section-number">3</span> Directed Acyclic Graphs and Causal Reasoning</a></li>
<li><a class="" href="spurious-association.html"><span class="header-section-number">4</span> Multiple regression - Spurious association</a></li>
<li><a class="" href="the-haunted-dag.html"><span class="header-section-number">5</span> The haunted DAG</a></li>
<li><a class="" href="information-criteria.html"><span class="header-section-number">6</span> Information Criteria</a></li>
<li><a class="" href="bayesian-vs.-fequentist-statisics.html"><span class="header-section-number">7</span> Bayesian vs. fequentist statisics</a></li>
<li><a class="active" href="mixtures.html"><span class="header-section-number">8</span> Mixtures</a></li>
<li><a class="" href="instrumental-variables.html"><span class="header-section-number">9</span> Instrumental Variables</a></li>
<li><a class="" href="parameters-combining-information-from-an-individual-with-population.html"><span class="header-section-number">10</span> Parameters: combining information from an individual with population</a></li>
<li><a class="" href="incorporating-measurement-error-a-rubber-band-metaphor.html"><span class="header-section-number">11</span> Incorporating measurement error: a rubber band metaphor</a></li>
<li><a class="" href="generalized-additive-models-as-continuous-random-effects.html"><span class="header-section-number">12</span> Generalized Additive Models as continuous random effects</a></li>
<li><a class="" href="flat-priors-the-strings-attached.html"><span class="header-section-number">13</span> Flat priors: the strings attached</a></li>
<li><a class="" href="unbiased-mean-versus-biased-variance-in-plain-english.html"><span class="header-section-number">14</span> Unbiased mean versus biased variance in plain English</a></li>
<li><a class="" href="probability-mass-versus-probability-density.html"><span class="header-section-number">15</span> Probability mass versus probability density</a></li>
<li><a class="" href="effective-degrees-of-freedom-number-of-parameters.html"><span class="header-section-number">16</span> Effective degrees of freedom / number of parameters</a></li>
<li><a class="" href="multiple-regression---masked-relationship.html"><span class="header-section-number">17</span> Multiple regression - Masked relationship</a></li>
<li><a class="" href="ordered-categorical-data-i.e.-likert-scales.html"><span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales</a></li>
<li><a class="" href="intuition-for-how-cholesky-decomposition-makes-possible-to-generate-correlated-random-variables.html"><span class="header-section-number">19</span> Intuition for how Cholesky decomposition makes possible to generate correlated random variables</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/alexander-pastukhov/notes-on-statistics">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="mixtures" class="section level1" number="8">
<h1>
<span class="header-section-number">8</span> Mixtures<a class="anchor" aria-label="anchor" href="#mixtures"><i class="fas fa-link"></i></a>
</h1>
<div id="beta-binomial" class="section level2" number="8.1">
<h2>
<span class="header-section-number">8.1</span> Beta Binomial<a class="anchor" aria-label="anchor" href="#beta-binomial"><i class="fas fa-link"></i></a>
</h2>
<p>Beta binomial is defined as a product of binomial and beta distributions.
<span class="math display">\[BetaBinomial(k|N, p, \theta) = Binomial(k|N,p) \cdot Beta(p|\beta_1, \beta_2),\]</span>
where <span class="math inline">\(k\)</span> is number of successes (e.g., “heads” in a coin toss), <span class="math inline">\(N\)</span> is total number of trials/draws, and <span class="math inline">\(p\)</span> is the probability of success), and <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> determine the shape of the beta distribution. The book uses reparametrized version of the beta distribution, sometimes called <em>beta proportion</em>:
<span class="math display">\[BetaBinomial(k|N, p, \theta) = Binomial(k|N,p) \cdot Beta(p|p, \theta),\]</span>
where <span class="math inline">\(\theta\)</span> is precision parameter. <span class="math inline">\(p\)</span> and <span class="math inline">\(\theta\)</span> can be computed from <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> as
<span class="math display">\[
p = \frac{\beta_1}{\beta_1 + \beta_2}\\
\theta = \beta_1 + \beta_2
\]</span>
The latter form makes it more intuitive but if you look at the code of <code>dbetabinom()</code>, you will see that you can use <code>shape1</code> and <code>shape2</code> parameters instead of <code>probe</code> and <code>theta</code>.</p>
<p>Recall the (unnormalized) Bayes rule (<span class="math inline">\(p\)</span> is probability, <span class="math inline">\(y\)</span> is an outcome, <span class="math inline">\(...\)</span> parameters of the prior distribution):
<span class="math display">\[
Pr(p | y) = Pr(y | p) \cdot Pr(p | ...)
\]</span>
Examine the formula again and you can see that you can think about beta binomial as a posterior distribution for a binomial likelihood with the beta distribution as prior for parameter <span class="math inline">\(p'\)</span> of the binomial distribution:</p>
<p><span class="math display">\[BetaBinomial(N, p, \theta | k) = Binomial(k|N,p) \cdot Beta(p| p_{mode}, \theta)\]</span></p>
<p>Thus, beta binomial is a combination of <em>all</em> binomial distributions weighted by a beta distribution that has its mode at <span class="math inline">\(p_{mode}\)</span> and its width is determined by <span class="math inline">\(\theta\)</span>. In other words, when we use binomial distribution alone, we state that we can <em>compute</em> the probability directly as <span class="math inline">\(p = \text{some linear model}\)</span>. Here, we state that our knowledge is incomplete and, <em>at best</em>, we can predict mode of the beta distribution from which this probability comes from and we let data determine variance/precision (<span class="math inline">\(\theta\)</span>) of that distribution. Thus, our posterior will reflect <em>two</em> uncertainties based on two loss functions: one about the number of observed events (many counts are compatible with a given <span class="math inline">\(p\)</span> but with different probabilities), as for the binomial, plus another one about <span class="math inline">\(p\)</span> itself (many values of <span class="math inline">\(p\)</span> are compatible with given <span class="math inline">\(p_{mode}\)</span> and <span class="math inline">\(\theta\)</span>). This allows model to compute a trade-off by considering values of <span class="math inline">\(p\)</span> that are less likely from prior point of view (they are away from <span class="math inline">\(p_{mode}\)</span>) but that result in higher probability of <span class="math inline">\(k\)</span> given that chosen <span class="math inline">\(p\)</span>. We will see the same trick again later in the book, when we will use it to incorporate uncertainty about measured value (i.e., at best, we can say that the actual observed value comes from a distribution with that mean and standard deviation).</p>
<p>In practical terms, this means that parameter <span class="math inline">\(\theta\)</span> controls the width of the distribution (see plots below). As <span class="math inline">\(\theta\)</span> approaches positive infinity, our prior uncertainty about <span class="math inline">\(p\)</span> is reduced to zero, which means that we now consider only one binomial distribution, where <span class="math inline">\(p' = p\)</span>, which is equivalent to the simple binomial distribution. Thus, beta binomial <em>at most</em> is as narrow as the binomial distribution.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/beta-binomial-1.png" width="672"></div>
</div>
<div id="negative-binomial-a.k.a.-gamma-poisson" class="section level2" number="8.2">
<h2>
<span class="header-section-number">8.2</span> Negative binomial, a.k.a. Gamma Poisson<a class="anchor" aria-label="anchor" href="#negative-binomial-a.k.a.-gamma-poisson"><i class="fas fa-link"></i></a>
</h2>
<p>The idea is the same: We do not have enough information to compute the rate of events, so instead, we compute the mean of the Gamma distribution rates come from and let data determine its variance (scale). Again, in practical terms this means that for the smallest scale our uncertainty about the rate is minimal and distribution matches the Poisson processes with a fixed rate. Any increase in uncertainty (larger values for scale parameter), mean broader distribution that is capable to account for more extreme values.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-32-1.png" width="672"></div>
</div>
<div id="ordered-categorical" class="section level2" number="8.3">
<h2>
<span class="header-section-number">8.3</span> Ordered categorical<a class="anchor" aria-label="anchor" href="#ordered-categorical"><i class="fas fa-link"></i></a>
</h2>
<p>From log odds to logit link.
<span class="math display">\[
log(\frac{Pr(y_i \leq k)}{1 - Pr(y_i \leq k)}) = \alpha_k \\
\frac{Pr(y_i \leq k)}{1 - Pr(y_i \leq k)} = e^{\alpha_k} \\
Pr(y_i \leq k) = e^{\alpha_k} \cdot ( 1 - Pr(y_i \leq k)) \\
Pr(y_i \leq k) \cdot ( 1 + e^{\alpha_k}) = e^{\alpha_k} \\
Pr(y_i \leq k) = \frac{e^{\alpha_k}}{1 + e^{\alpha_k}}
\]</span></p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">df_p</span> <span class="op">&lt;-</span>
  <span class="fu">tibble</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">10</span>, <span class="fl">10</span>, length.out<span class="op">=</span><span class="fl">100</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">mutate</span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="fu">ggplot</span><span class="op">(</span><span class="va">df_p</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">alpha</span>, y<span class="op">=</span><span class="va">p</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">geom_line</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-33-1.png" width="672"></div>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">equal_probability</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span> <span class="op">/</span> <span class="fl">7</span><span class="op">)</span> <span class="op">/</span>  <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span> <span class="op">/</span> <span class="fl">7</span><span class="op">)</span><span class="op">)</span>
  
<span class="va">df_ord_cat</span> <span class="op">&lt;-</span> 
  <span class="fu">tibble</span><span class="op">(</span>Response <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">7</span>, 
         p <span class="op">=</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/dordlogit.html">dordlogit</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">7</span>, <span class="fl">0</span>, <span class="va">equal_probability</span><span class="op">)</span>,
         Label <span class="op">=</span> <span class="st">"Equal probability"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">bind_rows</span><span class="op">(</span><span class="fu">tibble</span><span class="op">(</span>Response <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">7</span>, 
         p <span class="op">=</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/dordlogit.html">dordlogit</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">7</span>, <span class="fl">0</span>, <span class="va">equal_probability</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>,
         Label <span class="op">=</span> <span class="st">"Beta = 1"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">bind_rows</span><span class="op">(</span><span class="fu">tibble</span><span class="op">(</span>Response <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">7</span>, 
         p <span class="op">=</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/dordlogit.html">dordlogit</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">7</span>, <span class="fl">0</span>, <span class="va">equal_probability</span> <span class="op">+</span> <span class="fl">2</span><span class="op">)</span>,
         Label <span class="op">=</span> <span class="st">"Beta = -2"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">mutate</span><span class="op">(</span>Label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Label</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Beta = 1"</span>, <span class="st">"Equal probability"</span>, <span class="st">"Beta = -2"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="va">df_cuts</span> <span class="op">&lt;-</span>
  <span class="fu">tibble</span><span class="op">(</span>Response <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, 
         K <span class="op">=</span> <span class="va">equal_probability</span>,
         Label <span class="op">=</span> <span class="st">"Equal probability"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">bind_rows</span><span class="op">(</span><span class="fu">tibble</span><span class="op">(</span>Response <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, 
         K <span class="op">=</span> <span class="va">equal_probability</span> <span class="op">-</span> <span class="fl">1</span>,
         Label <span class="op">=</span> <span class="st">"Beta = 1"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">bind_rows</span><span class="op">(</span><span class="fu">tibble</span><span class="op">(</span>Response <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, 
         K <span class="op">=</span> <span class="va">equal_probability</span> <span class="op">+</span> <span class="fl">2</span>,
         Label <span class="op">=</span> <span class="st">"Beta = -2"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">mutate</span><span class="op">(</span>Label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Label</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Beta = 1"</span>, <span class="st">"Equal probability"</span>, <span class="st">"Beta = -2"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  

<span class="va">cuts_plot</span> <span class="op">&lt;-</span>
  <span class="fu">ggplot</span><span class="op">(</span>data<span class="op">=</span><span class="va">df_cuts</span>,<span class="op">)</span> <span class="op">+</span> 
  <span class="fu">geom_vline</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">K</span>, color<span class="op">=</span><span class="va">Label</span><span class="op">)</span>, show.legend <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">facet_grid</span><span class="op">(</span><span class="va">Label</span><span class="op">~</span><span class="va">.</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">scale_x_continuous</span><span class="op">(</span><span class="st">"Odds ratio"</span><span class="op">)</span>

<span class="va">prob_plot</span> <span class="op">&lt;-</span> 
  <span class="fu">ggplot</span><span class="op">(</span>data<span class="op">=</span><span class="va">df_ord_cat</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">Response</span>, y<span class="op">=</span><span class="va">p</span>, color<span class="op">=</span><span class="va">Label</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">geom_line</span><span class="op">(</span><span class="op">)</span>

<span class="va">cuts_plot</span> <span class="op">+</span> <span class="va">prob_plot</span></code></pre></div>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-34-1.png" width="672"></div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="bayesian-vs.-fequentist-statisics.html"><span class="header-section-number">7</span> Bayesian vs. fequentist statisics</a></div>
<div class="next"><a href="instrumental-variables.html"><span class="header-section-number">9</span> Instrumental Variables</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#mixtures"><span class="header-section-number">8</span> Mixtures</a></li>
<li><a class="nav-link" href="#beta-binomial"><span class="header-section-number">8.1</span> Beta Binomial</a></li>
<li><a class="nav-link" href="#negative-binomial-a.k.a.-gamma-poisson"><span class="header-section-number">8.2</span> Negative binomial, a.k.a. Gamma Poisson</a></li>
<li><a class="nav-link" href="#ordered-categorical"><span class="header-section-number">8.3</span> Ordered categorical</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/alexander-pastukhov/notes-on-statistics/blob/master/07-mixtures.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/alexander-pastukhov/notes-on-statistics/edit/master/07-mixtures.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Notes on Statistics</strong>" was written by Alexander Pastukhov. It was last built on 2022-06-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
