<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 15 Probability mass versus probability density | Notes on Statistics</title>
<meta name="author" content="Alexander Pastukhov">
<meta name="description" content="When you first encounter continuous distribution, one of the initially confusing things is the concept of probability density that looks like probability of an outcome (but is not) and the fact...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 15 Probability mass versus probability density | Notes on Statistics">
<meta property="og:type" content="book">
<meta property="og:description" content="When you first encounter continuous distribution, one of the initially confusing things is the concept of probability density that looks like probability of an outcome (but is not) and the fact...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 15 Probability mass versus probability density | Notes on Statistics">
<meta name="twitter:description" content="When you first encounter continuous distribution, one of the initially confusing things is the concept of probability density that looks like probability of an outcome (but is not) and the fact...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="bs4_style.css%20-%20style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Notes on Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Precis</a></li>
<li><a class="" href="loss-functions.html"><span class="header-section-number">2</span> Loss functions</a></li>
<li><a class="" href="directed-acyclic-graphs-and-causal-reasoning.html"><span class="header-section-number">3</span> Directed Acyclic Graphs and Causal Reasoning</a></li>
<li><a class="" href="spurious-association.html"><span class="header-section-number">4</span> Multiple regression - Spurious association</a></li>
<li><a class="" href="the-haunted-dag.html"><span class="header-section-number">5</span> The haunted DAG</a></li>
<li><a class="" href="information-criteria.html"><span class="header-section-number">6</span> Information Criteria</a></li>
<li><a class="" href="bayesian-vs.-fequentist-statisics.html"><span class="header-section-number">7</span> Bayesian vs. fequentist statisics</a></li>
<li><a class="" href="mixtures.html"><span class="header-section-number">8</span> Mixtures</a></li>
<li><a class="" href="instrumental-variables.html"><span class="header-section-number">9</span> Instrumental Variables</a></li>
<li><a class="" href="parameters-combining-information-from-an-individual-with-population.html"><span class="header-section-number">10</span> Parameters: combining information from an individual with population</a></li>
<li><a class="" href="incorporating-measurement-error-a-rubber-band-metaphor.html"><span class="header-section-number">11</span> Incorporating measurement error: a rubber band metaphor</a></li>
<li><a class="" href="generalized-additive-models-as-continuous-random-effects.html"><span class="header-section-number">12</span> Generalized Additive Models as continuous random effects</a></li>
<li><a class="" href="flat-priors-the-strings-attached.html"><span class="header-section-number">13</span> Flat priors: the strings attached</a></li>
<li><a class="" href="unbiased-mean-versus-biased-variance-in-plain-english.html"><span class="header-section-number">14</span> Unbiased mean versus biased variance in plain English</a></li>
<li><a class="active" href="probability-mass-versus-probability-density.html"><span class="header-section-number">15</span> Probability mass versus probability density</a></li>
<li><a class="" href="effective-degrees-of-freedom-number-of-parameters.html"><span class="header-section-number">16</span> Effective degrees of freedom / number of parameters</a></li>
<li><a class="" href="multiple-regression---masked-relationship.html"><span class="header-section-number">17</span> Multiple regression - Masked relationship</a></li>
<li><a class="" href="ordered-categorical-data-i.e.-likert-scales.html"><span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales</a></li>
<li><a class="" href="intuition-for-how-cholesky-decomposition-makes-possible-to-generate-correlated-random-variables.html"><span class="header-section-number">19</span> Intuition for how Cholesky decomposition makes possible to generate correlated random variables</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/alexander-pastukhov/notes-on-statistics">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="probability-mass-versus-probability-density" class="section level1" number="15">
<h1>
<span class="header-section-number">15</span> Probability mass versus probability density<a class="anchor" aria-label="anchor" href="#probability-mass-versus-probability-density"><i class="fas fa-link"></i></a>
</h1>
<p>When you first encounter continuous distribution, one of the initially confusing things is the concept of probability density that <em>looks like</em> probability of an outcome (but is not) and the fact that it can be any positive value, not just within 0 and 1. To make understanding easier, let us start with a simple concept of <em>probability mass</em>. Here, each outcome gets a probability that must be between 0 and 1 and probabilities for all outcomes must add up to 1 (makes these values probability rather than just plausibility). Imagine the simplest case when all events are equally likely. For example, I have four cubes and you must guess the height of the tower that I have built. There are five possible towers (zero-height tower is also a tower, just not a particularly good one) and without any prior knowledge you can assume that each tower height is equally likely: 1/N, where N=5, so 1/5 = 0.2 (or 20%, if you like percentages more).</p>
<p>There is another way of thinking about this via <em>cumulative mass function</em>. It tells a cumulative (total) probability of observing a height of a tower that is equal or smaller than a chosen value.</p>
<p><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-63-1.png" width="672">
As you can see, a cumulative probability of observing a tower of zero height (or lower) is 0.2. We if consider height of 1, it bumps cumulative probability to 0.4 (Pr(height=0) + Pr(height=1) = 0.2 + 0.2 = 0.4). Going up to 2 makes it 0.6, to 3 — 0.8 and, finally, the cumulative probability of me building a tower of height of 4 <em>or lower</em> is 1 (100%!). The latter includes <em>all</em> possible tower heights, so the probability you observe one of them is 100%. Note that for each height the <em>probability mass</em> tells you by how much the cumulative probability will increase. This probability mass as an change of cumulative probability will become important later.</p>
<p>Note that cumulative probability can only grow and <em>must</em> be between 0 and 1, as all probabilities cannot be negative and must sum up to 1 (otherwise, we call them plausibilities). Below is the same plot but now it includes impossible heights of -1 and 5. Their probabilities are 0, so the cumulative probability does not grow.
<img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-64-1.png" width="672"></p>
<p>But what if I build a “tower” out of <em>very fine sand</em>? For simplicity, let us assume that its height is also within a 0 to 4 (cubes height) range. But now, there are way more heights that my tower can have. If my sand is super fine, as is individual grains are infinitesimally small, there are <em>infinite</em> numbers of possible heights. Knowing that they are all equally likely sort of helps but you cannot compute a probability for each individual height: 1/N, where N=∞ mean 1/∞ ≈ 0. This is the annoying thing about infinities, they make computing things really hard<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;People tend to be scared of calculus which is all about limits when things become either infinitesimally small or large.&lt;/p&gt;"><sup>32</sup></a>. So, what do you do if you cannot compute a probability for an individual event/value (height)? You can still compute the <em>cumulative probability</em> of a tower being smaller or equal to a particular height! This is the cumulative function that you saw earlier, but the steps are now so fine that you cannot talk about sums but only about integrals. This is why it is now called the cumulative <em>density</em> function (CDF).
<img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-65-1.png" width="672"></p>
<p>Note that it looks fairly similar to the previous plot with cumulative probability for discrete events. It still grows from 0 to 1 but the steps are much finer. Yet we can still tell the probability of observing a tower of a height that is equal to or less than this. We start of at zero, because you cannot observe towers of negative height, so <em>all</em> tower heights from negative infinity up to zero have a total cumulative probability of 0<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Keep in mind that these values are based on our example of me building a tower. In other circumstances, negative values are possible.&lt;/p&gt;"><sup>33</sup></a>. If we pick the height of 4, then the <em>cumulative</em> probability of observing a tower that is equal-or-less is 1 because <em>all</em> must be that or smaller (that is how we defined it, there cannot be a tower higher than 4!). If we pick the middle of the interval (height = 2), the <em>cumulative</em> probability of observing a tower that is equal-or-smaller is 0.5. This is because we are using a uniform distribution, so half splitting height in half also gives us 50% chance. As you can see, cumulative probability density behaves the same way as the cumulative probability mass in the example above. Both are fairly straightforward, as long as you appreciate that they are about <em>all</em> outcomes up to the point of interest, not just a single event.</p>
<p>What about the probability <em>density</em> function (PDF)? Recall that the probability mass function tells you how much the cumulative probability <em>changes</em> when you “move to the right” to include the next outcome. Same thing here but for continuous cases a function that describes the rate of change is called a derivative. The formula for our continuous uniform distribution is
<span class="math display">\[CDF = \frac{1}{4} \cdot height\]</span>
(note that we are currently only thinking about a range of 0 to 4 to make things simpler). You can check that this is indeed the case by plugging in different heights. Its derivative with respect to height is
<span class="math display">\[\frac{\delta CDF}{\delta height} = \frac{1}{4}\]</span></p>
<p>Thus, we can now plot both CDF and PDF.
<img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-66-1.png" width="672">
You can reverse the logic and say that the cumulative density function is an <em>integral</em> of PDF, i.e., area under the curve up to each point. So, the total area under PDF (blue line) should end up being 1 (final value of CDF). This is easy to check for a rectangular like that, just multiply its width (height range of 4) by its height (probability density value of 0.25) and get that 1. Note that if you restrict your height=2 then CDF values is 0.5 and the area under blue line (PDF) is also 0.5 (compute!).</p>
<p>In the example above, probability density is constant at 0.25 and that makes it look “normal”, at least not surprising. But what if we restrict my tower-building, so I cannot build anything taller than 0.5 cubes (or meters, units are of little relevance here). Now, the CDF formula is (check!):
<span class="math display">\[CDF = 2 \cdot height\]</span></p>
<p>and for PDF:
<span class="math display">\[\frac{\delta CDF}{\delta height} = 2\]</span></p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-67-1.png" width="672"></div>
<p>Our constant PDF value is 2! Way above one, how come? Think about the slope and think about the area of rectangle: if its 0.5 units wide it must be 2 units tall to make are equal to 1. The point of this is probability density <em>is not</em> a probability and that you should not care about <em>absolute</em> values of probability density, only about <em>relative</em> values. If you feel that “adding up” values larger than 1 should not give you 1 at the end, yes, it is very counter-intuitive. Integrals, as other things that have to do with infinitely small or large numbers, are counter-intuitive. Thus, ignore the units, ignore the absolute values, just keep in mind that whenever it is higher, the more probable that specific value is. (But, again, there is no way to compute a meaningful probability for a <em>single</em> value).</p>

</div>

  <div class="chapter-nav">
<div class="prev"><a href="unbiased-mean-versus-biased-variance-in-plain-english.html"><span class="header-section-number">14</span> Unbiased mean versus biased variance in plain English</a></div>
<div class="next"><a href="effective-degrees-of-freedom-number-of-parameters.html"><span class="header-section-number">16</span> Effective degrees of freedom / number of parameters</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#probability-mass-versus-probability-density"><span class="header-section-number">15</span> Probability mass versus probability density</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/alexander-pastukhov/notes-on-statistics/blob/master/14-probability-mass-versus-density.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/alexander-pastukhov/notes-on-statistics/edit/master/14-probability-mass-versus-density.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Notes on Statistics</strong>" was written by Alexander Pastukhov. It was last built on 2022-06-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
